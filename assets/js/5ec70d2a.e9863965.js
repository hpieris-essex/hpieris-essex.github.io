"use strict";(self.webpackChunkessex_portfolio_ml=self.webpackChunkessex_portfolio_ml||[]).push([[2940],{2179:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>a,default:()=>c,frontMatter:()=>r,metadata:()=>s,toc:()=>d});var i=n(4848),o=n(8453);const r={sidebar_position:1},a=void 0,s={id:"unit-8/Reflection",title:"Reflection",description:"The training a neural network unit covered how ANNs learn through trial and error (Mayo, 2017), the role of back propagation, and the building blocks of ANNs. I had the opportunity to re-visit gradient descent. The knowledge and understanding provided through this unit makes me feel comfortable in my ability to explain how ANNs work at a granular level. I believe this foundational understanding is going to be quite useful as I\u2019m venturing into building more complex models. I also enjoyed writing the forum post on AI writers, a timely topic considering the widespread use of large language models in all aspects of content creation tasks.",source:"@site/docs/unit-8/Reflection.md",sourceDirName:"unit-8",slug:"/unit-8/Reflection",permalink:"/unit-8/Reflection",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:1,frontMatter:{sidebar_position:1},sidebar:"tutorialSidebar",previous:{title:"8. Training an Artificial Neural Network",permalink:"/category/8-training-an-artificial-neural-network"},next:{title:"Discussion \u2014 Risks and benefits of the use AI writers [Initial Post]",permalink:"/unit-8/Risks & Benefits Of AI Writers"}},l={},d=[];function u(e){const t={a:"a",p:"p",...(0,o.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(t.p,{children:"The training a neural network unit covered how ANNs learn through trial and error (Mayo, 2017), the role of back propagation, and the building blocks of ANNs. I had the opportunity to re-visit gradient descent. The knowledge and understanding provided through this unit makes me feel comfortable in my ability to explain how ANNs work at a granular level. I believe this foundational understanding is going to be quite useful as I\u2019m venturing into building more complex models. I also enjoyed writing the forum post on AI writers, a timely topic considering the widespread use of large language models in all aspects of content creation tasks."}),"\n",(0,i.jsx)(t.p,{children:"References"}),"\n",(0,i.jsxs)(t.p,{children:["Mayo, M. (2017) Neural Network Foundations, Explained: Updating Weights with Gradient Descent & Backpropagation. Available from: ",(0,i.jsx)(t.a,{href:"https://www.kdnuggets.com/2017/10/neural-network-foundations-explained-gradient-descent.html",children:"https://www.kdnuggets.com/2017/10/neural-network-foundations-explained-gradient-descent.html"})," [Accessed 19 February 2024]."]})]})}function c(e={}){const{wrapper:t}={...(0,o.R)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(u,{...e})}):u(e)}},8453:(e,t,n)=>{n.d(t,{R:()=>a,x:()=>s});var i=n(6540);const o={},r=i.createContext(o);function a(e){const t=i.useContext(r);return i.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function s(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:a(e.components),i.createElement(r.Provider,{value:t},e.children)}}}]);