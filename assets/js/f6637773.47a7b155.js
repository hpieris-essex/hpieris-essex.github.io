"use strict";(self.webpackChunkessex_portfolio_ml=self.webpackChunkessex_portfolio_ml||[]).push([[5330],{3059:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>u,frontMatter:()=>r,metadata:()=>a,toc:()=>c});var i=t(4848),s=t(8453);const r={sidebar_position:1},o=void 0,a={id:"ml-docs/unit-4/Reflection",title:"Reflection",description:"Linear regression with Scikit-Learn provided the opportunity to re-vist this popular library and freshen-up my understanding. I have used Scikit-Learn library often in the past. However, recently my focus has been on transformer-based models \u2014 a type of deep learning models that utilizes self-attention mechanisms to process sequential data (Vaswani et al., 2017). Coming back to Scikit-Learn and reviewing fundamentals such as Linear Regression helped me fully appreciate the importance of these building blocks in more advanced machine learning models.",source:"@site/docs/ml-docs/unit-4/Reflection.md",sourceDirName:"ml-docs/unit-4",slug:"/ml-docs/unit-4/Reflection",permalink:"/ml-docs/unit-4/Reflection",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:1,frontMatter:{sidebar_position:1},sidebar:"tutorialSidebar",previous:{title:"4. Linear Regression with Scikit-Learn",permalink:"/category/4-linear-regression-with-scikit-learn"},next:{title:"Code & Tasks",permalink:"/ml-docs/unit-4/"}},l={},c=[];function d(e){const n={a:"a",p:"p",...(0,s.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.p,{children:"Linear regression with Scikit-Learn provided the opportunity to re-vist this popular library and freshen-up my understanding. I have used Scikit-Learn library often in the past. However, recently my focus has been on transformer-based models \u2014 a type of deep learning models that utilizes self-attention mechanisms to process sequential data (Vaswani et al., 2017). Coming back to Scikit-Learn and reviewing fundamentals such as Linear Regression helped me fully appreciate the importance of these building blocks in more advanced machine learning models."}),"\n",(0,i.jsx)(n.p,{children:"References"}),"\n",(0,i.jsxs)(n.p,{children:["Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A., Kaiser, L. & Polosukhin, I. (2017) Attention Is All You Need. Available from: ",(0,i.jsx)(n.a,{href:"https://doi.org/10.48550/arXiv.1706.03762",children:"https://doi.org/10.48550/arXiv.1706.03762"})," [Accessed 19 February 2024]."]})]})}function u(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>o,x:()=>a});var i=t(6540);const s={},r=i.createContext(s);function o(e){const n=i.useContext(r);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),i.createElement(r.Provider,{value:n},e.children)}}}]);