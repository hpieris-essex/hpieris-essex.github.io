# Code & Tasks


### Gradient Descent Cost Function

Gradient descent is an optimization algorithm used to minimize the cost function in machine learning models by iteratively moving towards the direction of the steepest decrease in cost or error.

In this activity I experimented with various epochs and learning rates to observe how the values are changing with these hyperparameter changes.

<a href="https://github.com/hpieris-essex/hpieris-essex.github.io/blob/ml-module/docs/unit-8/Gradient_Descent_Cost_Function.ipynb" target="_blank">Colab Notebook: Gradient Descent Cost Function</a>
<br/>