---
sidebar_position: 1
---

The case of "Malicious Inputs to Content Filters" focuses on the ethical issues faced by Blocker Plus, a content filtering system, as it integrated machine learning (ML) to comply with the U.S. Children’s Internet Protection Act (CIPA). The machine learning model in this case was exploited by activist groups, resulting in unjustified blocking of content related to topics such as gay marriage and vaccination, thus violating multiple ethical standards.

The ACM Code of Ethics mandates responsibility in design and deployment, especially with complex systems like ML, under Principles 2.5 and 2.9. Blocker Plus failed in these areas by neglecting safeguards against intentional misuse, which impacted legitimate public discourse. This oversight led to discrimination, violating Principles 1.2 and 1.4, which stress the avoidance of harm and fairness, respectively (ACM, 2018). In comparison, the BCS Code of Conduct emphasizes professional competence and integrity, requiring members to avoid any actions that injure others as well as public interest – specifically “conduct your professional activities without discrimination on the grounds of sex, sexual orientation, marital status, nationality, color, race, ethnic origin, religion, age or disability, or of any other condition or requirement.” (BCS, 2022). Blocker Plus's response to the exploitation—disabling accounts rather than addressing the root cause—failed to uphold professional responsibility. Both the ACM and BCS codes demand transparency, which Blocker Plus violated by not adequately disclosing the system's limitations to stakeholders. This violated ACM principles 1.3, 2.4 and 2.7 (ACM, 2018). In addition, this also violated the section 3.e from the BCS code of conduct (BCS, 2022).

This case highlights the need for robust safeguards when deploying ML in public systems and the importance of transparency to maintain trust and accountability in professional practice. The failures of Blocker Plus reflect poorly on the professionalism of those involved, illustrating a breach of ethical standards crucial in both the ACM and BCS codes.

#### References

ACM. (2018) Case: Malicious Inputs to Content Filters. Available from: https://ethics.acm.org/code-of-ethics/using-the-code/case-malicious-inputs-to-content-filters [Accessed 21 October, 2024].

BCS. (2022) BCS Code of Conduct. Available from: https://www.bcs.org/membership-and-registrations/become-a-member/bcs-code-of-conduct [Accessed 21 October 2024].


